Pedagogical perspectives on the use of technology within medical curricula: moving away from norm driven implementation 
 
Gabrielle M. Finn1 and Joanna Matthan2 

Keywords: technology, curriculum, medicine, learning, research, visualisation, pedagogy, education, students, learners, educator, TEL, technology-enhanced learning

Abstract
There is often an expectation that any educational institution worth its salt will be at the forefront of technological advances. An often unchallenged and somewhat romanticised viewpoint persists that, in all cases, technology is best. What is not always openly discussed is the evidence base and pedagogy behind the use of technology, visualisation and traditional approaches of teaching within the fields of medical and anatomy education curricula. There are many advantages to using technology within the learning environment but, often, it is possible to achieve the same outcomes through the use of many other non-technological instructional modalities. The frequent shortcoming when institutions use technology is that there is a lack of integration across the curriculum, a failure to map to the blueprint, little attempt to include technology in the feedback cycle and assessment, and insufficient time and resource allocation for educators developing resources. Without careful implementation and integration, it can appear that institutions are throwing the latest developments at students without due care and consideration to the evidence-base and without the necessary institutional support for staff and resource development. This is not the fault of educators; the competing demands on staff time and institutional drive to climb the ranking tables means that technology is often perceived as the quick fix. 

1. Technology within curricula 
Technology, once an advance on the education landscape, is now mainstream and at the core of medical education – as well as education more broadly. Educators are bombarded with arguments as to why the latest technology must be implemented in order to optimise the learning experience for ‘generation X’ or the ‘digitally native’ student populus, with the widespread unchallenged assumption that ‘millennials’ require on-demand technology-enhanced learning resources (Roberts et al, 2012). Little contest is given to the idea that technology enhances learning, or indeed to the notion that programmes ‘need’ technology to ensure student acceptability. This chapter considers the frequently unattested viewpoint that technology always enhances learning.

1.1. What does technology offer the learner, and what does it not?
There are pros and cons to most things in life – technology being one such commodity. Technological advances are often lauded as revolutionary, cutting edge or at the forefront of innovation – this is likely true. A plethora of literature supports the idea that technological tools can foster students' abilities, revolutionise students’ thinking, take their work to another level, provide them with new access to the world, support meaningful learning, facilitate collaborative learning, and enable the presentation of both dynamic and spatial images to portray relationships among complex concepts (Peck, 1994; Dori et al, 2005; Resta and Laferrière, 2007). 

2. Technology within the context of a medical curriculum
Technology is omnipresent and permeates every level of modern medical curricula. A typical undergraduate medical programme will include a host of technological enhancements, in addition to the traditional small and large group delivery methods. Virtual learning environments, such as Blackboard, provide learners with spaces for collating a range of course material utilising textual and visual learning material. Across institutions, lectures may be recapped to enable students to revisit tricky concepts at their leisure, some lectures are even relayed in real-time across sites, allowing students the option of either synchronous or asynchronous participation. Student response systems, such as TurningPoint and OMBEA, encourage students to engage more within large lectures, with the underlying assumption made that learner engagement equates with improved learning and retention. Learners may be encouraged to use their own devices in learning environment, or devices may be provided to enable engagement; these direct educators to gauging the pitch at which to deliver concepts. Educators may be encouraged to develop self-directed material for students using custom-made software or by utilising desktop capture technology, in a move to more self-directed learning and less face-to-face contact time. 

Social media sites, such as YouTube, supply a constant stream of education channels, some institution endorsed, to target learning in specific specialisms, with resounding evidence that external digital learning resources are embedded into the learning toolkit available to medical students (Scott et al, 2017). Further, educators may utilise social media such as Twitter, Facebook, Instagram and Snapchat to provide fora for discussion or dissemination of material related to their teaching or their wider academic interests, despite the shelf-life of numerous platforms being unpredictable – hundreds have cropped up and disappeared into oblivion since the start of the millennium (Guckian and Spencer, 2018; Dijck, 2013). Feedback software systems allowing students to see comprehensive breakdowns of their exam performance may also be utilised to guide further learning. Simulation and video playback technology may further enhance learning in the latter years of the curriculum, utilising both expensive and resource-heavy technology to deliver teaching and learning in safe environments and provide the opportunity for expert feedback, or self assessment (Phillips et al, 2016). Although technology has been utilised very little in assessment, institutions increasingly utilise software such as Turnitin to prevent plagiarism and a surge in essay mills, with a recent surge in developmental projects seeking to incorporate more technology into the assessment process. Learners at all levels are encouraged to utilise well-established commercial exam banks with thousands of exam questions to improve their multiple choice response skills, leading to the establishment of free versions with questionable and unvalidated content that may inadvertently be detrimental to learners’ knowledge base.

The widespread assumption prevalent in the education industry is that all learners have access to technology (not least, the financial means to pay for unlimited access to data and devices), want to use it and thrive in environments that endorse its use, with little institutional consideration for current and future stakeholders from widening access backgrounds (Delgaty et al, 2016). Beetham and White (2013) postulate that there is little understanding of how and why future university students will be using technology and, as institutions are encouraged to diversify their intake, themes around social equity and the digital divide (Lee, 2017) must feature in universities’ digital strategies to avoid inadvertently disadvantaging those stakeholders whose default is already one of disadvantage (Delgaty et al, 2016).  

2.1. Freely edited content and a call for integration
Undoubtedly, technology makes information more readily available – whether it be at the click of a button or the swipe of a finger across a screen – an almost infinite number of resources are freely accessible. Of course, the counter to that, as Herring (2001) presents, is that the internet, unlike a physical library, does not have quality control. Herring also reminds readers that not everything is online, and that an online search may be analogous to searching for a needle in a haystack. The internet delivers information on the move, with unlimited access hours and no overdue book fines – it is not difficult to see why students love the internet as their primary source of information. 

The internet has many excellent resources, and it thus becomes the duty of educators to upskill students in exercising criticality and caution when choosing sources and deciding on what is correct, but also in keeping themselves abreast of the constant barrage of new resources and applications, both freely available and commercial, and to potential dangers lurking in their lack of continued professional curiosity with regards to technological advancements in the field. Wikipedia is one such example – educators the world over will be sick of hearing, ‘but it says on Wikipedia that…’, or reading a bibliography with Wikipedia as the most cited source. 

A ‘wiki’ (noun) is a website or database developed collaboratively by a community of users, allowing any user to add and edit content. Wikipedia is the largest and most infamous wiki. What most users do not realise is that anyone can edit wikis. The editor of any given page could in fact by the world authority on a topic; however, it could also be someone with no credentials on the topic at all. Whether it is the duty of educators to ensure students are aware of limited rigour and quality control of freely available internet information, or whether it is the responsibility of the reader to consider the credibility of the sources they review is a contentious debate. Collaborative medical education learning resources, such as mediwikis, endorsed by medical organisations and colleges, do have verified content uploaded but this does not necessarily hold true for the majority of wikis. The point is that, while technology makes information easily accessible, it may not always present information that is correct or trusted. Naturally, the definition of a wiki for this chapter was looked up on Wikipedia, leaving the reader to decide on its veracity (Wikipedia, 2018). In recent years, the reliability of Wikipedia has been challenged. A report published in Nature claimed that the information provided on Wikipedia was almost as reliable as that of the Encyclopedia Britannica (Giles, 2005). Another study found that Wiki articles were on a par with professionally edited databases for health-care professionals. Readers were warned to err on the side of caution when turning to Wikipedia as a primary source of scientific information, the authors suggest that it is read critically and ‘with the understanding that the content is dynamic and vulnerable to vandalism and other shenanigans’ (Wilson and Likens, 2015).

Wikis are a collaborative space – provided that they are not constructed in isolation. With careful, considered constructive alignment to the curriculum, they can be a tool for fostering peer relationships, for shared learning and, for integration of cognitive knowledge. They offer a tool for constructing new knowledge, sharing existing knowledge and linking technology to assessment as group efforts can be assessed for formative and summative purposes. Wikis are an example of the best and the worst that technology has to offer – a space to share but one that may be unregulated and therefore facilitate the sharing of fundamentally incorrect ideas, to the detriment of the learners. For online educational programmes, wikis can drive programme integration from the curriculum outline to the assessment blueprint and to the learning communities created – but they must be regulated, with authors held accountable for inaccuracies in their work. 

A major limitation in the use of technology within education is that it is often limited to delivery and fails to feature in the feedback cycle or the assessment toolkit. Simple technological interventions, such as video playback, can be incorporated into the feedback cycle with good results (Phillips et al, 2016; Rammell et al, 2018) but the institutional commitment required to integrate it into the toolkit available to educators is somewhat lacking. When technology does feature in assessment, it is not integrated and its optimal functions utilised, but rather a basic tool for test administration. Simulation is one such example of the failure to integrate technology and assessment. Simulation within medical education has become extremely high fidelity, with enormous effort and resource invested in its use. The limitation is that simulation is most frequently restricted to use as a learning opportunity, rather than being integrated into the assessment structures and portfolios of institutions; this seems diametrically opposed to the rationale behind the implementation of simulation, real-world experiences for students, which should include assessments. A clear action point for technology enthused readers is to think carefully about how you map technology within your curriculum, ensuring its use is proportionate, representative and integrated.  

3. Is technology the vehicle for learning?
Within medical education, there is a long accepted view that learning anatomy from cadavers is the optimum method. Anything else, whether it be technology, plastic models, or an artistic approach such as body painting, is merely an adjunct. This viewpoint is often presented in the absence of evidence, prone to educators’ biases based on their own educational experiences and preferences. Within the school based education literature, there is a philosophy of thought that teachers who readily integrate technology into their classroom are more likely to possess constructivist teaching styles (Judson, 2006). Constructivism theories suggest that knowledge and meaning are constructed from the experiences of learners. It is important to note that constructivism is not a specific pedagogy. The implication from the link between the use of technology and constructivist approaches to pedagogy is that teachers who employ a constructivist-mindset maintain dynamic, student-centered classrooms, where technology is a powerful learning tool (Judson, 2006). Through constructivism, the student transforms from a passive recipient of information or cognitive knowledge into an individual who is actively participating in the learning process. What drives this process – is it the technology or the teacher, or both? 

3.1. What does technology add that other modalities do not?
Only the most cynical educator will fail to appreciate the manifold opportunities afforded by technological advances. For the learner, numerous technological educational interventions have led to greater levels of engagement with key curricular material. Several widely utilised interventions offer learners incredible ease of access and the possibility to engage with the learning process in real-time or asynchronously across time and place. The lure of the screen to capture the attention of the learner is unparallelled, and the perception that learning is taking place while, sometimes, passively receiving information appeals to our sense of laziness and desire to learn with minimal effort. In fact, so common is the lure to utilise the internet and other readily available resources, it has led to a phenomenon known as digital amnesia (more commonly known as Google effect, Sparrow et al, 2011) or the tendency to forget information easily accessible utilising internet search engine such as Google due to the belief that the material is always at hand and available online. For the educator, technological advances offer limitless possibilities to enhance the learning experience for students and to present foundational knowledge in newer and more innovative ways. Institutionally, technology and the perception that it is widely utilised may impact on the all-important student satisfaction rates. So considerable and limitless are the digital opportunities for education that a national membership organisation is at the forefront providing digital solutions for education and research (JISC, 2018). JISC recommends institutions and educators alike embrace technology, share discoveries, use time-saving technology, and sharing material across institutions. Their vision for technology usage in education is all about joined-up thinking, where for instance teaching and assessment are linked within an institution but also between institutions, and collaboration with others leads to seamless integration of technology into our everyday education.

4. Technology is not always better
One technology often found within the anatomists’ toolkit is the portable ultrasound. Ultrasound machines have become cheaper and therefore more mainstream. Griksaitis et al (2012) challenged the view that cadaveric anatomy was optimal when teaching gross anatomy of the heart by conducting a randomised control trial. The intervention was the use of portable ultrasound, the control was typical cadaveric anatomy teaching using prosections – the industry gold standard, so to speak. The study concluded that prosections and ultrasound are equally effective methods for teaching gross anatomy of the heart, as both of the teaching modalities used increased students’ post-test scores by similar amounts but no significant difference was found between the two conditions. The authors advocated the inclusion of either cadaveric teaching or living anatomy using ultrasound within the undergraduate anatomy curriculum. 

The aforementioned example perhaps highlights the notion that no teaching modality is ever truly superior. If one unpicks the learning experience surrounding the use of ultrasound, many advantages and disadvantages could be postulated. Firstly, students experience living anatomy as the scan is performed on a live volunteer. They get introduced to a technology that will be commonplace in the clinical environment that they will work within once qualified. They get introduced to ultrasound images and how to interpret them. Perhaps using the ultrasound machine helps reaffirm part of their current identity or helps in forming their future professional identity and exploring future career options within medicine. On the flipside, the ultrasound is limited to certain views due to the position of the probe and the depth of the scan. Students can struggle conceptually when working with such an advanced technology, and papers have highlighted a plethora of issues from greyscales images, probe orientation, and knobology to physics (Griksaitis et al., 2012; Griksaitis et al, 2014; Finn et al, 2012).  

There is sometimes, what could be described as, a romanticised viewpoint that merely the presence of technology within educational environments will enhance the learning of students and their levels of attainment (National Research Council, 2000). It is possible that what technology actually offers is something that is different, out of the ordinary and thus perhaps more memorable and engaging. In the fields of medical education and biomedical visualisation, technology brings an entirely different, and otherwise impossible to visualise view of the human body or, in fact, multiple viewpoints of the body at every possible angle and orientation, readily accessible in laboratories, lecture theatres and on hand-held devices. There are a multitude of expensive, but highly sophisticated, technologies such as virtual autopsy tables and 3D dissection software that enable the user to rotate, dissect or project the human body in the blink of an eye. These available technologies within anatomical education offer many advantages: human tissue and the associated licences are not required (except during the initial creation of some software products), there are fewer emotional or sensitive issues related to death and dying associated with virtual anatomies, and multiple users can interact simultaneously with some select technologies. However, it is not just technology that presents such advantages, and modalities utilising art-based approaches may also possess such attributes – this will be explored subsequently. 

4.1. A comparison between technology and art 
As this book centres on visualisation, let us consider something of significant visual impact – anatomical body painting. The use of body painting within anatomy teaching is well documented (Finn and McLachlan, 2010; Finn, 2015; Cookson et al, 2018; Aka et al, 2018). A full critical appraisal of its effectiveness is not the remit of this chapter; however, a few ideas pertinent to the discussion will be shared. 

Body painting enables learners to work collaboratively, both by painting anatomy onto a peer, and by allowing a peer to act as the painted canvas. Otherwise ‘invisible’ internal structures become visible on the canvas of the body without the need for cadaveric anatomy. There are many more advantages, and naturally disadvantages. Essentially, it all boils down to the fact that the learning experience is different, more hands-on and engaging than a traditional cadaver-based session, and the facilitators of such sessions are arguably more enthusiastic about delivering sessions that are not run-of-the-mill for them and during which their may be able to interact with their learners in novel ways, exactly the same selling points as the technology delivered visualisation in the former example. 

The commonalities between the two examples are that both break the monotony of long practical sessions in the laboratory or lectures delivered in dulcet tones. The sessions are more lighthearted than is possible in the understandably highly governed dissecting room environment, present opportunities for near-peer teaching and promote accessibility to a broader audience of users. It is important to acknowledge that both are likely to have their own hidden curriculum associated with their use (Aka et al, 2018). 

5. Simulated learning and gamification: Is high fidelity always best?
Simulation has all the components of a game (goals, rules, challenge and interaction). Learners (its players) are tasked with achieving the preset educational learning outcomes. Simulation is used within medical education to enable interactive, and where possible, immersive activities that aim to recreate all or elements of a clinical experience without exposing patients or peers to any of the associated risks. As we know, there are a range of  technologies used in simulation which fall on a spectrum from simple task training models to extremely sophisticated computer and technology driven models (Maran and Galvin, 2003), all designed to represent clinical situations required to train, assess, and evaluate the knowledge of human systems and error (Reis et al, 2018). These approaches purport to develop participants’ cognitive abilities, and psychomotor and interpersonal skills, with high-fidelity simulations being the widely accepted gold standard within this simulation ecosystem.

In a study looking at the context dependent learning, Finn and colleagues (2010) found that using low fidelity simulation, clinical clothing to be specific, aided recall of knowledge in medical students. The study concluded that low fidelity, but authentic, simulation could have a significant impact on learning. Many other studies have looked at high fidelity simulations and the impact on learning but as Gordon and colleagues (2001) state, when considering implementing simulation, students’ ability to practice without risk must be weighed against the cost of this new technology. Increasing popularity of simulation teaching methods has meant it is widely utilised in medical education but a downside is that it has been suggested that learners now know “how to play the simulation game”, where they perform solely for the simulated setting with none of the skills learnt transferring into the workplace. 

6 The black box of educational research: Is technology-enhanced learning problematic for us?
Enhancement of learning and educational attainment – as well as innovation in education – is sometimes perceived to be solely possible in the presence of technological interventions (National Research Council, 2000). This barely evidenced notion persists throughout the educational sector, although there is a growing body of less technology-enthused educators who argue that investments in technology are a financial and temporal drain, and a waste of students’ valuable time (Levy, 1997) with no measurable learning gain. These polarised views remain prevalent through medical education, although educators persist in adopting new technologies into their learning and teaching practice indiscriminately, without scrutinising the available evidence on the efficacy of the new technology (or assessing it for efficacy and usefulness). E-learning serves as an example on this indiscriminate usage. It has been extensively researched but the evidence shows little improvement on traditional instruction and its uptake by academics (mainly in traditional institutions) is marginal (Cook, 2009). Workloads on distance learning courses are often unsustainable for educators, and faculty workload assumptions from the past are inaccurate (Hovenga and Bricknell, 2006; Delgaty, 2014). Further, online learning represents discontinuity with previous practice, resulting in role crisis and ambiguity to academics (Briggs, 2005) and the erosion of autonomy and academic freedom (Beaudoin, 1990). The ‘glorious revolution’ of e-Learning appears to not be happening, clamouring for more clarity on when it is appropriate to incorporate this method of learning into educational interventions and highlighting the failure of e-learning research to inform educational practice. 

When choosing to integrate technology into education, one may look to the literature for evidence to support such inclusion. Of course, this is good practice. What perhaps is given less consideration is the black box of educational literature. The black box metaphor is often used with reference to studies that report inputs and outputs but not the mechanism and inner workings of interventions (Pinch, 1992), although the same metaphor is occasionally used for studies that are rejected or not submitted for publication due to negative results (Pinch, 1992). A growing body of literature illuminates some of the manifold limitations of technology-enhanced learning, and the use of technology in medical education remains poorly understood (Wong et al, 2010). Academics are often socialised into only reporting positive results, negative findings are dismissed as not publishable and thus vanish into the black box of educational literature, never to see the light of day. Many of the published research papers are not rigorous in their research design and the information filtering out into the wider sphere of educational research may be selected to only report positive results with technological interventions, not those that fail to impress or show a marked difference to learners (Cook, 2009; Clunie et al, 2017). Incorporation of technology into delivery of teaching is mistakenly perceived as synonymous with innovation (Delgaty et al, 2017) but indiscriminate use of technology may have unexpected downsides and prove hazardous, especially when it may come at the expense of a reduction in meaningful contact time and a range of other better-evaluated or tried and tested learning methods. The point is this, when considering implementing technology, using the literature to inform decision making is a must, but critical appraisal of the learning mechanisms behind the results must be given just as much consideration. Inputs do not necessarily equate to outputs, question cause and effect. Is it really the technology that is improving the learning experience? Of course, the answer may well be yes. The implementation of the any new instructional tool, whether technological in nature or not, should be based upon assimilation of evidence and best practice, rather than the desire to keep up with the status quo. 

Some newer technology from the gaming industry offers learners with a fully immersive learning experience. Virtual reality (VR) and augmented virtual reality is a case in point. These environments are deemed safe and engaging educational settings where advanced learning can take place without patients coming to any harm and failure is not frowned upon. Yet, incorporation of VR into teaching requires investment on multiple levels and is riddled with obstacles. Issues with devices, compatibility, storage limitations and app and browser capabilities abound. Digital fluency and device types of the learners are rarely homogenous, and this diversity makes supporting learners an onerous undertaking. Not all learners are digitally savvy and mobile technology may also be challenging to some. Virtual reality sickness may also prevent learners from making full use of this technology in their learning. Not only are these environments and their educational impact poorly researched but they also highlight to educators the pitfalls of technology, where one size certainly does not fit all.

6.1 Digital distraction and cyber-slacking
Part of the lure of widespread use of technology is the belief that it intuitively leads to better engagement and subject retention. Concerns have been raised on how technology is eroding an acceptable knowledge base. We know that students' attitudes tend to be influenced by numerous factors such as escapism, consumerism, inattention, and distraction by peers’ cyber-slacking behavior (Taneja et al, 2015). Inattention may be influenced by intrinsic and extrinsic apathy, lack of motivation, or wider classroom engagement. Samson (2010) found that laptop usage improved students' levels of attentiveness and engagement in class. However, the flipside of this widespread usage is that access to technology provides an easy route to completely disengage from the learning environment. The same students who use technology to engage in learning will also engage in other activities that have little or no relation to what is being taught (Fried 2008; Ragan et al, 2014; Ravizza et al, 2014), and access to distracting social media sites is enabled by this ease of access through device usage in the classroom setting. A backlash against laptops surfaced (Schwartz, 2003) but today laptop usage is widespread in education, although there is some evidence to suggest that use of laptops for note-taking in lectures is not as effective for retention of material learnt as handwritten notes (Mueller and Oppenheimer, 2014). 

7. Three-dimensional printing as an example of norm driven implementation 
One new technologies that has emerged in recent years is three-dimensional (3D) printing. 3D printing has been used for multiple purposes, but is popular within anatomy education. 3D prints of bones are common, created from surface scans and medical images. Bones lend themselves to printing as they are a hard structure and monochromatic. These features make them easy to print, with accurate results that preserve the visual and haptic qualities of the real tissue (AbouHashem et al, 2015). This 3D printing technology clearly has many advantages: portability of the scans, artefacts are created that students can keep, colour can be used to promote learning, pathologies and variations can be printed. As with all technologies, there are issues with cost, ink jets clogging, etc. Interestingly, the 3D prints are used like any other anatomical model, whereby students examine and rotates the specimen in order to study the anatomies. Some institutions print white copies so that students can draw on neurovasculature.  The 3D printing approach rapidly produces multiple, anatomically accurate reproductions of anatomies at any size and  scale, use of which avoids  some of the cultural and ethical issues associated with cadaver specimens (McMenamin, 2015).  

3D printing is a fantastic technological advancement, it has many benefits for teaching and learning but it is another prime example , in some cases, of implementation without evidence. Many institutions chose to invest significant sums of money in 3D printers without consideration of how the technology is integrated into the programme of study, with little thought to assessment and the pedagogy involved in using printed artefacts and with consideration of a literature base primarily based upon student satisfaction. The 3D printing example highlights the gap in good quality, educational randomised control trials, whereby the effectiveness can truly be assessed. Of course, acceptability with students is of importance too but it should not be the driver for all change and innovation.

Educational research needs to continue building momentum, be better supported by funders and ensure rigour and quality. Buckingham (2005) state that ‘educational research is often far from sound’. The reason she gives for this view is the current preference within education faculties for producing qualitative rather than, and at the expense of, quantitative research​. The National Academy of Science evaluated educational research generically, and found "methodologically weak research, trivial studies, an infatuation with jargon, and a tendency toward fads with a consequent fragmentation of effort" (Atkinson & Jackson, 1992). It is therefore the duty of those considering embedding anything enw into their curriculum, to make a judgement on the quality of the evidence base that they consult when making such decisions. Questions needs to be asked as to whether the implementation is norm or criterion driven? If it is a case of ‘everyone does the same​’, there is a new realm of educational activity, whether that be a new technology being utilised or a change to an assessment structure, but no true progression​. The use of our teaching modalities becomes norm driven, departments have the equipment so they must use it​. It is this set of actions that devalues the research​. It is a reflexive devaluation which then drives the devaluation further as the as it not used. 

All hope is not lost, as Norman (2002) described in the British Medical Journal, and research in medical education has contributed substantially to understanding the learning process​. The educational community is becoming aware of the importance of evidence in educational decision making​. That being said, real improvement in education, just like real improvements in medical treatments, will only result when we combine better the understanding of basic science with the experimental interventions (Norman, 2002).​ 
​​
Conclusion
New technologies bring with them radical opportunities but there are also signiﬁcant often neglected and ill-considered challenges. This chapter has presented some of these challenges, or perhaps, better described as opportunities for growth and change. It is important to appreciate that technology-enhanced learning is not a magic bullet with which to plug the holes of programmes with pedagogical flaws or student satisfaction concerns. It cannot be a panacea for foundational curricular imperfections. Instead, it offers enhancement to already existing learning methods and, sometimes, can offer truly unique learning experiences that offer variation to the oftentimes mundane arsenal of learning tools available to the educator. Considered and targeted use of digital technologies can present new material in novel ways through a variety of learning tools with which to engage learners. 

To truly embed technology within medical programmes in a meaningful manner, pedagogical interventions need to be continually assessed and revised, and coupled with a research-led approach to TEL. Significant institutional investments should support embedding selected evidence-based TEL interventions into programmes, with the necessary educator workload concerns and time constraints addressed, and with sufficient technology support at hand and institutional training and development opportunities readily available. Learners should be at the core of any interventions, and digital policies must be inclusive and consider the wider stakeholder capabilities and financial constraints. 

What does the future hold for further technology-enhancement of medical education? The possibilities seem limitless and staggering. Already, there is talk about the enhancement of learning through artificial intelligence, truly immersive virtual reality and telepresence robots. Big data is bringing with it the possibility to build and target learning using analytics, and there is talk of next generation learning environments and intelligent campuses. To enable this level of change - if desired - “technology leaders need to work together with educators, not as missionaries bearing magical gifts, but as collaborators in creating new opportunities to learn. It will take a concerted effort to bring about such a radical change in thinking.” (Collins and Halverson, 2010)  Practice and pedagogy must walk hand in hand with technology innovation and higher-level institutional commitments to realise some of these enhancement measures in a manner that is valuable for learners but also meaningful for educators.
